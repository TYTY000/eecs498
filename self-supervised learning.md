自监督学习并不那么地注重准确率，我们更多的使用这种方法来获取计算产生的中间产物，如数据特征，它可以用于下流任务，这才是重点。
因此，自监督学习的方法并不好评价，我们只能依靠于实验和结果。
#distortion
旋转、平移、缩放等等
#patches
![[self-sup-by-relative-position.png]]
#colorization
The model outputs colors in the the CIE Lab* color space. The Lab* color is designed to approximate human vision, while, in contrast, RGB or CMYK models the color output of physical devices.

L* component matches human perception of lightness; L* = 0 is black and L* = 100 indicates white.
a* component represents green (negative) / magenta (positive) value.
b* component models blue (negative) /yellow (positive) value.

tf-idf（英語：term frequency–inverse document frequency）是一種用於資訊檢索與文本挖掘的常用加權技術。tf-idf是一種統計方法，用以評估一字詞對於一個文件集或一個語料庫中的其中一份文件的重要程度。字詞的重要性隨著它在文件中出現的次數成正比增加，但同時會隨著它在語料庫中出現的頻率成反比下降。tf-idf加權的各種形式常被搜索引擎應用，作為文件與用戶查詢之間相關程度的度量或評級。除了tf-idf以外，互聯網上的搜尋引擎還會使用基於連結分析的評級方法，以確定文件在搜尋結果中出現的順序。 
#Split-Brain_Autoencoder
![[Pasted image 20240325140919.png]]![[Pasted image 20240325140928.png]]
它能够综合地获取各个通道对图像信息的有效部分。
#pretext
生成预文本（Generative Pretexts）是一种用于训练神经网络的无监督学习方法，通常用于预训练模型，然后在下游任务中进行微调。


 预训练和微调：
        在生成预文本中，模型首先在大规模无标签数据上进行预训练。这通常涉及到自编码器、生成对抗网络（GANs）或其他生成模型。
        预训练的目标是学习有用的表示，以便在下游任务中进行微调。

 细节和表示：
        生成预文本的问题在于，它鼓励模型关注数据中的细节，而这些细节对于下游任务可能并不重要。
        例如，如果模型被训练来生成图像，它可能会花费大量容量来捕捉每个像素的微小变化，而这些变化在分类、分割或其他任务中并不重要。

过度拟合：
        如果模型过于关注细节，它可能会过度拟合预训练数据，从而在下游任务中表现不佳。
        模型可能会记住训练数据中的噪声，而不是真正有用的特征。

权衡：
        在使用生成预文本时，需要权衡模型的容量和任务的需求。
        有时，模型可能会过度关注细节，而忽略了更高级别的抽象特征。
判别性预文本任务（Discriminative Pretext Tasks）是一种解决生成预文本可能导致模型关注不重要细节的方法。让我详细解释一下：

#discriminative_pretext_tasks
在判别性预文本任务中，模型被要求执行分类任务，而不是生成任务。
例如，可以使用图像分类、目标检测或其他分类任务作为预训练的目标。

关注重要特征：判别性任务鼓励模型关注对分类任务有用的特征。例如，在图像分类中，模型需要学习区分不同类别的特征，这通常涉及到更高级别的抽象。
减少过拟合：相对于生成任务，判别性任务更容易避免过度关注细节。因为分类任务通常需要更广泛的特征，而不是精确的像素级别细节。
更好的迁移性：判别性任务的表示通常在下游任务中具有更好的迁移性，因为它们更接近实际应用中的需求。

#deep_clustering
1.随机初始化1个CNN
2.扔进很多图像，获取其最终层的特征
3.用K-means来分类
4.不断聚类的loss，进行模型优化。

#contrastive_learning
对比学习（Contrastive Learning）是一种自监督学习方法，它的目标是：将一个样本的不同的、增强过的新样本们在嵌入空间中尽可能地近，然后让不同的样本之间尽可能地远。在图像任务中，对比学习通常会对输入的图像进行增强（例如，颜色变换、几何变换等），然后让模型学习区分原图和增强图像1。这种方法可以帮助模型学习到更具区分度的图像特征，从而提高任务的准确性和鲁棒性2。所以，你的理解是正确的，对比学习确实会对输入的图像进行增强。
一个简单的例子：![[Pasted image 20240325144120.png]]
很明显，这样很容易造成过拟合。其中，t是一个温度参数，用于控制分布的尖锐程度。这个损失函数的形式与交叉熵损失函数相似，因此可以解释为在其他2N−1个元素中进行交叉熵损失。

为什么说NLP的SSL比CV的效果要好很多？
语言的信息密度：语言确实具有很大的信息密度。一个单词或短语可以包含大量的信息，这使得NLP的SSL能够从相对较小的数据集中学习到丰富的信息。
文本天生就是带有标签的数据：这是一个很好的观察。在NLP中，每个单词都可以看作是一种标签，这使得自监督学习可以在大量的无标注文本数据中进行。
语言的抽象程度足够高：语言的抽象程度确实很高，这使得模型需要理解更深层次的语义和语境信息，而这正是自监督学习擅长的。
图像的数据更加难以处理：图像数据的处理确实比文本数据更为复杂。图像数据的维度通常更高，而且图像的语义信息往往需要通过复杂的模型才能提取出来。

#zero-shot_classifcation
零样本分类
![[Pasted image 20240325150547.png]]
