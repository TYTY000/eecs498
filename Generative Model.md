条件生成式模型（Conditional Generative Model）是生成式模型的一种扩展，它在生成器和判别器的输入中增加了额外的条件信息1。这种模型不仅仅是随机生成数据，而是希望能够控制生成的数据1。

具体来说，条件生成式模型的生成器的输入不仅有潜在分布，还有一个确定的条件变量1。例如，如果我们的训练样本是人类的头像，条件是男性和女性，训练结束后的条件生成式模型可以通过指定条件来生成男性或女性的头像2。

在条件生成式模型中，生成器生成的图片只有在足够真实且与条件相符的情况下，才能通过判别器的“审查”1。这样的模型在许多生成对抗网络（GAN）的应用中都有所体现1。例如，条件生成对抗网络（Conditional GAN，简称CGAN）就是条件生成式模型的一个典型应用1。在CGAN中，生成器和判别器的输入都包含了条件信息，使得生成的数据能够满足特定的条件1。这种模型可以用于各种任务，如图像翻译、人脸属性编辑等1。总的来说，条件生成式模型提供了一种在生成数据时引入条件约束的方法，使得生成的数据可以满足特定的需求1。
![[Pasted image 20240314160925.png]]

#autoencoder
![[Pasted image 20240314162504.png]]
![[Pasted image 20240314163021.png]]
**自编码器有点类似一个降维再升维、损失精度/信息的操作，不过它可以更有效的处理高维信息。**
*After training, throw away decoder and use encoder for a downstream task*
![[Pasted image 20240314164056.png]]
监督式学习的玩法。
它最大的问题是不能产生新数据，它的目标是学习数据的有效表示（特征）
#variational_AE
![[Pasted image 20240314170817.png]]

概率性自编码器：引入了概率分布的概念。VAE 的目标是学习数据的潜在表示（latent representation），并且能够从这个潜在表示中生成新的数据样本。
学习潜在特征 z：VAE 的第一步是从原始数据中学习潜在特征 z。这些特征可以理解为数据的隐含属性，例如图像的方向、颜色等。
采样过程：在训练完成后，我们可以使用 VAE 模型来生成新的数据样本。这个过程涉及两个步骤：
从条件分布中采样：我们可以使用已知的潜在特征 z 来生成对应的数据样本 x，即 pθ∗(x | z)。
先验分布中采样：我们也可以直接从先验分布 pθ∗(z) 中采样一个潜在特征 z。
先验分布：VAE 假设潜在特征 z 的先验分布是简单的，例如高斯分布。
神经网络表示：VAE 使用神经网络来表示条件分布 p(x|z)，类似于自编码器中的解码器。

使用高斯噪声来引入微小的随机性，通过解码器的神经网络叠加，VAE 可以从潜在表示 z 中重建出数据样本 x，同时也可以从先验分布中采样新的潜在特征 z，从而生成全新的数据。
![[Pasted image 20240314171315.png]]
![[Pasted image 20240314171544.png]]
之后的内容：看不懂
#GAN 
![[Pasted image 20240315145059.png]]
![[Pasted image 20240315145426.png]]
